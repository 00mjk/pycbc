#!/usr/bin/env python

# Copyright (C) 2011 Ian W. Harry
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 3 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

"""
Stochastic aligned spin bank generator.

List of possible improvements:
   * When not running with --vary-flower the code does not need to do use all
     of the xi_i coordinates. Even for TaylorR2F4 more than 4 of the coordinates
     would not be needed. For F2 3 is fine everywhere we've tested. This would
     provide a speed up.
   * It would be interesting to see whether the biggest cost is in generating
     the points, or in calculating matches. Both with an without --vary-flower
   * I don't know why covary and vary-flower couldn't be used together. You
     would only covary the coordinate system with largest f_upper, so matches
     are not covaried. BUt the covaried coordinates can be used to minimize
     the number of matches being calculated.
"""

from __future__ import division
import matplotlib
matplotlib.use('Agg')
import pylab
import time
startET = time.time()
elapsed_time = lambda: time.time() - startET

import os,sys,optparse,copy
import tempfile
import ConfigParser
import numpy
import pycbc.version
import pycbc.tmpltbank
import pycbc.psd
import pycbc.frame
import pycbc.filter
import pycbc.strain
import pycbc.types
from glue import pipeline
from glue.ligolw.utils import process as ligolw_process
import lal
LAL_PI = lal.LAL_PI
LAL_MTSUN_SI = lal.LAL_MTSUN_SI

__author__  = "Ian Harry <ian.harry@astro.cf.ac.uk>"
__version__ = pycbc.version.git_verbose_msg
__date__    = pycbc.version.date
__program__ = "pycbc_aligned_stoch_bank"

# Read command line options
usage = """usage: %prog [options]"""
_desc = __doc__[1:]
parser = optparse.OptionParser(usage, version=__version__, description=_desc,\
           formatter=pycbc.tmpltbank.IndentedHelpFormatterWithNL())

# Begin with code specific options
parser.add_option("-v", "--verbose", action="store_true", default=False,\
                    help="verbose output, default: %default")
parser.add_option("-O", "--output-file",  help="Output file name."+\
                                          "REQUIRED ARGUMENT.")
parser.add_option("-m", "--min-match", action="store", type="float",\
                  default=None, help="Minimum match to generate bank with."+\
                                      "REQUIRED ARGUMENT")
parser.add_option("-V", "--vary-fupper", action="store_true", default=False,\
                    help="Set this to run the code using a variable f_upper."\
                   +"OPTIONAL: default= %default")
parser.add_option("-N", "--num-seeds", action="store", type="int",\
                  default=5000000,\
                  help="Number of seed points to make bank," +\
                       "OPTIONAL: default= %default")
parser.add_option("-c", "--covary", action="store_true", default=False,\
                    help="Set this to run with covaried coordinates. This will"\
                   +"provide a speed up, but cannot run with varying f-lower"\
                   +"yet. OPTIONAL: default= %default")
parser.add_option("-n", "--num-failed-cutoff", action="store", type="int",\
                  default=1000000000, help="Give up after having tested this "+\
                  "many consecutive points each of which were not accepted "+\
                  "into the bank. OPTIONAL: default= %default (this is "+\
                  "really large as --num-seeds provides the default "+\
                  "termination condition.")

# Insert the metric calculation options
pycbc.tmpltbank.insert_metric_calculation_options(parser)

# Insert the mass range options
pycbc.tmpltbank.insert_mass_range_option_group(parser)

# Insert the PSD options
pycbc.psd.insert_psd_option_group(parser)

# Insert the data reading options
pycbc.strain.insert_strain_option_group(parser)

# Add the ethinca calculation options
pycbc.tmpltbank.insert_ethinca_calculation_option_group(parser)

(opts,args) = parser.parse_args()

# Sanity check options
if not opts.output_file:
    parser.error("Must supply --output-file")
if not opts.min_match:
    parser.error("Must supply --min-match")
opts.max_mismatch = 1 - opts.min_match
pycbc.tmpltbank.verify_metric_calculation_options(opts, parser)
metricParams=pycbc.tmpltbank.metricParameters.from_optparse(opts)
pycbc.tmpltbank.verify_mass_range_options(opts, parser)
massRangeParams=pycbc.tmpltbank.massRangeParameters.from_optparse(opts)
pycbc.psd.verify_psd_options(opts, parser)
if opts.psd_estimation:
    pycbc.strain.verify_strain_options(opts, parser)
pycbc.tmpltbank.verify_ethinca_calculation_options(opts, parser)

# FIXME: Move to noise.from_cli when its written
# If we are going to use h(t) to estimate a PSD we need h(t)
if opts.psd_estimation:
    if opts.verbose:
        print >>sys.stdout, "Obtaining h(t) for PSD generation at %f" \
                            %(elapsed_time())
    strain = pycbc.strain.from_cli(opts)
else:
    strain = None

# Get the PSD using the pycbc interface
if opts.verbose:
    print >>sys.stdout, "Obtaining PSD at %f." %(elapsed_time())
# Want the number of samples to be a binary number and Nyquist must be above
# opts.f_upper. All this assumes that 1 / deltaF is a binary number
nyquistFreq = 2**numpy.ceil(numpy.log2(opts.f_upper))
numSamples = int(round(nyquistFreq / opts.delta_f)) + 1
psd = pycbc.psd.from_cli(opts, length=numSamples, delta_f=opts.delta_f, \
                         low_frequency_cutoff=opts.f_low, strain=strain)
metricParams.psd = psd

# Begin by calculating a metric
metricParams = pycbc.tmpltbank.determine_eigen_directions(\
    metricParams, \
    vary_fmax=(opts.vary_fupper or opts.calculate_ethinca_metric),\
    vary_density=opts.ethinca_calc_density)

# Choose the discrete values of frequencies to use if --vary-fupper is used
if not (opts.vary_fupper or opts.calculate_ethinca_metric):
    refFreq = metricParams.fUpper
elif opts.calculate_ethinca_metric and not opts.vary_fupper:
    fs = numpy.array(metricParams.evals.keys(), dtype=float)
    fs.sort()
    refFreq = fs.max()
else:
    fs = numpy.array(metricParams.evals.keys(), dtype=float)
    fs.sort()
    maxTMass = opts.max_total_mass
    minTMass = opts.min_total_mass
    lowEve = pycbc.tmpltbank.return_nearest_isco(\
               numpy.array([maxTMass]), fs)[0]
    highEve = pycbc.tmpltbank.return_nearest_isco(\
                numpy.array([minTMass]), fs)[0]
    refFreq = lowEve

if opts.verbose:
    print >>sys.stdout, "Calculating covariance matrix at %f." \
                        %(elapsed_time())

vals = pycbc.tmpltbank.estimate_mass_range(1000000,\
       massRangeParams, metricParams, refFreq, covary=False)
cov = numpy.cov(vals)
evalsCV,evecsCV = numpy.linalg.eig(cov)
metricParams.evecsCV = {}
metricParams.evecsCV[refFreq] = evecsCV    

if opts.verbose:
    print>> sys.stdout, "Covariance matrix calculated at %f." \
                        %(elapsed_time())

# Estimate the largest values of \chi_1 and \chi_2 to optimise what follows
if opts.verbose:
    print>> sys.stdout, "Determining parameter space extent %f."\
                        %(elapsed_time())

vals = pycbc.tmpltbank.estimate_mass_range(1000000,\
       massRangeParams, metricParams, refFreq, covary=True)

chi1Max = vals[0].max()
chi1Min = vals[0].min()
chi1Diff = chi1Max - chi1Min
chi2Max = vals[1].max()
chi2Min = vals[1].min()
chi2Diff = chi2Max - chi2Min
# FIXME: Maybe better to use the numerical code to find maxima here?
chi1Min = chi1Min - 0.1*chi1Diff
chi1Max = chi1Max + 0.1*chi1Diff
chi2Min = chi2Min - 0.1*chi2Diff
chi2Max = chi2Max + 0.1*chi2Diff


if opts.verbose:
    print>> sys.stdout, "Determined parameter space extent %f."\
                        %(elapsed_time())


if opts.verbose:
    print>> sys.stdout, "Initializing bank set up at %f." %(elapsed_time())

vals = None

# Set up the bank into sections
massbank = {}
bank = {}
MMdist = (opts.max_mismatch)**0.5
for i in range(-2,int((chi1Max - chi1Min) // MMdist + 2)):
    bank[i] = {}
    massbank[i] = {}
    for j in range(-2,int((chi2Max - chi2Min) // MMdist + 2)):
        bank[i][j] = []
        massbank[i][j] = []

# Initialise counters
N = 0
Np = 0
Ns = 0
Nr = 0

# Map the frequency values to idx if --vary-fupper is used
if opts.vary_fupper:
    freqMap = {}
    idx = 0
    for freq in fs:
        if freq >= lowEve and freq <= highEve:
            freqMap[freq] = idx
            idx += 1

if opts.verbose:
    print>> sys.stdout, "Initialized bank and starting at %f." %(elapsed_time())

# Begin making the thing
outbins = [[0,0],[0,1],[1,0],[0,-1],[-1,0],[1,1],[1,-1],[-1,1],[-1,-1]]
while(1):
    if not (Ns % 100000):
        # For optimization we generate points in sets of 100000
        rTotmass, rEta, rBeta, rSigma, rGamma, rSpin1z, rSpin2z =\
            pycbc.tmpltbank.get_random_mass(100000, massRangeParams)
        diff = (rTotmass*rTotmass * (1-4*rEta))**0.5
        rMass1 = (rTotmass + diff)/2.
        rMass2 = (rTotmass - diff)/2.
        rChis = (rSpin1z + rSpin2z)/2.
        if opts.vary_fupper:
            refEve = pycbc.tmpltbank.return_nearest_isco(rTotmass, fs)
            lambdas = pycbc.tmpltbank.get_chirp_params(rTotmass, rEta, rBeta,\
                      rSigma, rGamma, rChis, metricParams.f0, \
                      metricParams.pnOrder)
            mus = []
            idx = 0
            for freq in fs:
                if freq >= lowEve and freq <= highEve: 
                    mus.append(pycbc.tmpltbank.get_mu_params(lambdas,\
                                                          metricParams, freq))
                    if freqMap[freq] != idx:
                        raise BrokenError
                    idx += 1
            mus = numpy.array(mus)
        else:
            refEve = numpy.zeros(100000)
            mus = numpy.zeros([1,1,100000])
        vecs = pycbc.tmpltbank.get_cov_params(rTotmass, rEta, rBeta,\
                   rSigma, rGamma, rChis, metricParams, refFreq)
        vecs = numpy.array(vecs)
        Ns = 0
    # Then we check each point for acceptance
    if not (Np % 10000) and opts.verbose:
        print "Seeds",Np
    vs = vecs[:,Ns]
    # What bin should it be in?
    v1Bin = int((vs[0] - chi1Min) // MMdist)
    v2Bin = int((vs[1] - chi2Min) // MMdist)
    store = True
    Np = Np + 1
    # Stop if we hit break condition
    if Np > opts.num_seeds:
        break
    # Calculate if any existing point is too close (set store to False)
    if opts.vary_fupper:
        for i,j in outbins:
            if store:
                for entry in massbank[v1Bin+i][v2Bin+j]:
                    if pycbc.tmpltbank.calc_point_dist_vary(\
                                 mus[:,:,Ns], refEve[Ns], entry[5], entry[4],\
                                 freqMap, opts.max_mismatch):
                        store = False
                        break
    else:
        for i,j in outbins:
            if store:
                for entry in bank[v1Bin+i][v2Bin+j]:
                    if pycbc.tmpltbank.calc_point_dist(vs, entry,\
                                                       opts.max_mismatch):
                        store = False
                        break
    # Increment counters, check for break condition and continue if rejected
    if not store:
        Ns = Ns + 1
        Nr = Nr + 1
        if Nr > opts.num_failed_cutoff:
            break
        continue
    # Add point, increment counters and continue if accepted
    Nr = 0
    bank[v1Bin][v2Bin].append(copy.deepcopy(vs))
    massbank[v1Bin][v2Bin].append([copy.deepcopy(rMass1[Ns]),\
          copy.deepcopy(rMass2[Ns]), copy.deepcopy(rSpin1z[Ns]),\
          copy.deepcopy(rSpin2z[Ns]), copy.deepcopy(refEve[Ns]),\
          copy.deepcopy(mus[:,:,Ns])])
    N = N + 1
    if opts.verbose and not (N % 100000):
        print "Templates %d at %f" %(N,elapsed_time())
    Ns = Ns + 1  

if opts.verbose:
    print "Outputting at %f." %(elapsed_time())

# Put the whole template bank in one list
tempBank = []
for i in range(-2,int((chi1Max - chi1Min) // MMdist + 2)):
    for j in range(-2,int((chi2Max - chi2Min) // MMdist + 2)):
        for masses in massbank[i][j]:
            tempBank.append([masses[0],masses[1],masses[2],masses[3]])


# Output to file
pycbc.tmpltbank.output_sngl_inspiral_table(opts.output_file, tempBank, 
         metricParams, calculate_ethinca_comps=opts.calculate_ethinca_metric,\
         programName=__program__,optDict=opts.__dict__,\
         comment="", ifos=[""], version=pycbc.version.git_hash,\
         cvs_repository='pycbc/'+pycbc.version.git_branch,\
         cvs_entry_time=pycbc.version.date)

# All this is useful for debugging
#outfile=open('stochastic_bank_mass.dat','w')
#outfile2=open('stochastic_bank_evs.dat','w')

#for i in range(int((chi1Max - chi1Min) // MMdist)):
#    for j in range(int((chi2Max - chi2Min) // MMdist)):
#        for entry in bank[i][j]:
#            outfile2.write('%.16e %.16e %.16e %.16e %.16e %.16e %.16e %.16e\n' %(entry[0],entry[1],entry[2],entry[3],entry[4],entry[5],entry[6],entry[7]))
#outfile2.close()

#for i in range(int((chi1Max - chi1Min) // MMdist)):
#    for j in range(int((chi2Max - chi2Min) // MMdist)):
#        for masses in massbank[i][j]:
#            outfile.write('%.16e %.16e %.16e %.16e\n' %(masses[0],masses[1],masses[2],masses[3]))
#outfile.close()
