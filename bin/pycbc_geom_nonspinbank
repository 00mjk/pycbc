#!/usr/bin/env python

# Copyright (C) 2013 Ian W. Harry
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 3 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

"""
Template bank generator for placing a bank of non-spinning templates.
"""

# Imports
from __future__ import division
import os,sys,optparse,math,copy
import numpy
import pycbc.version
from glue.ligolw import ligolw
from glue.ligolw import table
from glue.ligolw import lsctables
from glue.ligolw import utils as ligolw_utils
from glue.ligolw.utils import process as ligolw_process
import pycbc.psd
import pycbc.frame
import pycbc.filter
import pycbc.types
import pycbc.tmpltbank
import time
startET = time.time()
elapsed_time = lambda: time.time()-startET

__author__  = "Ian Harry <ian.harry@ligo.org>"
__version__ = pycbc.version.git_verbose_msg
__date__    = pycbc.version.date
__program__ = "pycbc_geom_nonspinbank"

# Read command line options
usage = """usage: %prog [options]"""
_desc = __doc__[1:]
parser = optparse.OptionParser(usage, version=__version__, description=_desc)
parser.add_option("-v", "--verbose", action="store_true", default=False,\
                    help="verbose output, default: %default")
parser.add_option("-o", "--pn-order", action="store", type="string",\
                   default=None,\
                   help="""Determines the PN order to use, choices are:
    * "twoPN": will include terms up to 2PN in phase
    * "threePointFivePN": will include terms to 3.5PN
    * "taylorF4_45PN": use the R2F4 metric with partial terms to 4.5PN""")
parser.add_option("-f", "--f0", action="store", type="float",\
                  default=70., help="f0 for use in metric calculation," +\
                                    "default: %default")
parser.add_option("-l", "--f-low", action="store", type="float",\
                  default=15., help="f_low for use in metric calculation," +\
                                    "default: %default")
parser.add_option("-u", "--f-upper", action="store", type="float",\
                  default=2000., help="f_up for use in metric calculation," +\
                                      "default: %default")
parser.add_option("-d", "--delta-f", action="store", type="float",\
                  default=0.001, help="delta_f for use in metric calculation,"+\
                                      "linear interpolation used to get this,"+\
                                      "default: %default")
parser.add_option("-m", "--min-match", action="store", type="float",\
                  default=0.03, help="Minimum match to generate bank with"+\
                                      "default: %default")
parser.add_option("-y", "--min-mass1", action="store", type="float",\
                  default=None, help="Minimum mass1 to generate bank with"+\
                                     ", mass1 *must* be larger than mass2" +\
                                      "default: %default")
parser.add_option("-Y", "--max-mass1", action="store", type="float",\
                  default=None, help="Maximum mass1 to generate bank with"+\
                                      "default: %default")
parser.add_option("-z", "--min-mass2", action="store", type="float",\
                  default=None, help="Minimum mass2 to generate bank with"+\
                                      "default: %default")
parser.add_option("-Z", "--max-mass2", action="store", type="float",\
                  default=None, help="Maximum mass2 to generate bank with"+\
                                      "default: %default")
parser.add_option("", "--max-total-mass", action="store", type="float",\
                  default=None, help="Minimum total mass to generate bank "+\
                                      "with default: %default")
parser.add_option("", "--min-total-mass", action="store", type="float",\
                  default=None, help="Maximum total mass to generate bank "+\
                                      "with default: %default")
parser.add_option("-O", "--output-file",  help="Output file name")

pycbc.psd.insert_psd_option_group(parser)

dataReadingGroup = optparse.OptionGroup(parser, "Options for obtaining h(t)",
                  "These options are used for generating h(t) either by "
                  "reading from file or by generating it. This is only needed "
                  "if the PSD is to be estimated from the data, ie. if the "
                  "--psd-estimation option is given.")

dataReadingGroup.add_option("--gps-start-time", \
                            help="The gps start time of the data", type=int)
dataReadingGroup.add_option("--gps-end-time", \
                            help="The gps end time of the data", type=int)
dataReadingGroup.add_option("--strain-high-pass", type=float, \
                            help="High pass frequency")
dataReadingGroup.add_option("--pad-data", \
              help="Extra padding to remove highpass corruption (s)", type=int)
dataReadingGroup.add_option("--sample-rate", type=int, \
                            help="The sample rate to use for h(t) generation.")
dataReadingGroup.add_option("--frame-cache", type=str, \
                            help="Cache file containing the frame locations.")
dataReadingGroup.add_option("--channel-name", type=str, \
                   help="The channel containing the gravitational strain data")
parser.add_option_group(dataReadingGroup)

ethincaGroup = optparse.OptionGroup(parser, "Ethinca metric options",
                    "These options are used in the calculation of the gamma  "
                    "components for ethinca calculations if needed.")
ethincaGroup.add_option("","--calculate-ethinca-metric", action="store_true",\
                        default=False, help="If given the ethinca metric "+\
                        "will be calculated and stored in the Gamma entried "+\
                        "in the sngl_inspiral table.")
ethincaGroup.add_option("","--ethinca-calc-density", action="store",\
                        default=10, help="The ethinca metric is calculated "+\
                        "using a given value for f_max. Tmpltbank uses the "+\
                        "ISCO frequency for every template and recomputes "+\
                        "the metric components every time it does this. "+\
                        "This code generates the metric for discrete values "+\
                        "f_max and uses the closest one to each template's "+\
                        "ISCO frequency. This value sets the spacing between "+\
                        "these discrete values of frequency cutoff. "+\
                        "default: %default")
parser.add_option_group(ethincaGroup)


(opts,args) = parser.parse_args()

# Sanity check options
if not opts.pn_order:
    parser.error("Must supply --pn-order")
if not opts.min_mass1:
    parser.error("Must supply --min-mass1")
if not opts.min_mass2:
    parser.error("Must supply --min-mass2")
if not opts.max_mass1:
    parser.error("Must supply --max-mass1")
if not opts.max_mass2:
    parser.error("Must supply --max-mass2")
if not opts.output_file:
    parser.error("Must supply --output-file")

if (not opts.min_total_mass) or \
        ((opts.min_mass1 + opts.min_mass2) > opts.min_total_mass):
    opts.min_total_mass = opts.min_mass1 + opts.min_mass2
if (not opts.max_total_mass) or \
        ((opts.max_mass1 + opts.max_mass2) < opts.max_total_mass):
    opts.max_total_mass = opts.max_mass1 + opts.max_mass2


maxSpinMag = 0

# If we are going to use h(t) to estimate a PSD we need h(t)
if opts.psd_estimation:
    # FIXME: It would be nice if this was similar to psd.from_cli()
    if opts.verbose:
        print >>sys.stdout, "Obtaining h(t) for PSD generation at %f" \
                            %(elapsed_time())
    # Actually read in the frame
    strain = pycbc.frame.read_frame(opts.frame_cache, opts.channel_name, 
                        start_time=opts.gps_start_time-opts.pad_data, 
                        end_time=opts.gps_end_time+opts.pad_data)

    # Applying a high pass filter
    strain = pycbc.filter.highpass(strain, frequency=opts.strain_high_pass)

    # Change the dynamic range and convert from double to single
    strain = (strain * pycbc.DYN_RANGE_FAC).astype(pycbc.types.float32)

    # Resample the data (from 16384 -> 4096Hz)
    strain = pycbc.filter.resample_to_delta_t(strain, 1.0/opts.sample_rate)

    # Removing padding
    start = opts.pad_data*opts.sample_rate
    end = len(strain)-opts.sample_rate*opts.pad_data
    strain = strain[start:end]
else:
    strain = None

# Get the PSD using the pycbc interface
if opts.verbose:
    print >>sys.stdout, "Obtaining PSD at %f." %(elapsed_time())
# Want the number of samples to be a binary number and Nyquist must be above
# opts.f_upper. All this assumes that 1 / deltaF is a binary number
nyquistFreq = 2**numpy.ceil(numpy.log2(opts.f_upper))
numSamples = int(round(nyquistFreq / opts.delta_f)) + 1

psd = pycbc.psd.from_cli(opts, length=numSamples, delta_f=opts.delta_f, \
                         low_frequency_cutoff=opts.f_low, strain=strain)

if opts.verbose:
    print >>sys.stdout, "Calculating metric at %f." %(elapsed_time())

# Begin by calculating a metric
evals, evecs, _, moments = pycbc.tmpltbank.determine_eigen_directions(\
    psd, opts.pn_order, opts.f0, opts.f_low, opts.f_upper, opts.delta_f,\
    vary_fmax=opts.calculate_ethinca_metric,\
    vary_density=opts.ethinca_calc_density)

# This is used to calculate evalsCV and evecsCV with describe the rotations
# needed to move into the principal component directions. evalsCV will be 1s.
if opts.verbose:
    print >>sys.stdout, "Calculating covariance matrix at %f." %(elapsed_time())

vals = pycbc.tmpltbank.estimate_mass_range(1000000,\
       opts.pn_order, evals[opts.f_upper], evecs[opts.f_upper], opts.max_mass1,\
       opts.min_mass1, opts.max_mass2, opts.min_mass2,\
       maxSpinMag, opts.f0, covary=False, maxBHspin=maxSpinMag,\
       minTotalMass=opts.min_total_mass, maxTotalMass=opts.max_total_mass)
cov = numpy.cov(vals)
evalsCV, evecsCV = numpy.linalg.eig(cov)

if opts.verbose:
    print>> sys.stdout, "Covariance matrix calculated at %f." %(elapsed_time())

# This is to get an estimate of the largest values of \chi1 and \chi2
vals = pycbc.tmpltbank.estimate_mass_range(5000000,\
       opts.pn_order, evals[opts.f_upper], evecs[opts.f_upper], opts.max_mass1,\
       opts.min_mass1, opts.max_mass2, opts.min_mass2,\
       maxSpinMag, opts.f0, covary=True, evecsCV=evecsCV, \
       maxBHspin=maxSpinMag, \
       minTotalMass=opts.min_total_mass, maxTotalMass=opts.max_total_mass)

chi1Max = vals[0].max()
chi1Min = vals[0].min()
chi1Diff = chi1Max - chi1Min
chi2Max = vals[1].max()
chi2Min = vals[1].min()
chi2Diff = chi2Max - chi2Min

# Generate a lattice of points in \chi1 \chi2 coordinates
if opts.verbose:
    print>> sys.stdout, "Calculating lattice at %f." %(elapsed_time())

# When placing the lattice we transition from 1D lattice to a hexagonal
# lattice and then back to 1D lattice
# Assume that once 2D is needed it will be needed until the end. 
# Ie. We have 1D region then 2D region then 1D region. Nothing else
# Length of the 1D region can be 0

# We start by figuring out the 1D lattice regions and placing these 1D lattices
# Start from the start going forward.

lower1DBoundary = None
spacing1D = opts.min_match**0.5 * 2
v1s = []
v2s = []
for i in range(100):
    tempChi1Lower = chi1Min + i * chi1Diff/100.
    tempChi1Upper = chi1Min + (i+1) * chi1Diff/100.
    lgc = (vals[0] > tempChi1Lower) & (vals[0] < tempChi1Upper)
    tempChi1 = vals[0][lgc]
    tempChi2 = vals[1][lgc]
    tempChi2Max = tempChi2.max()
    tempChi2Min = tempChi2.min()
    if (tempChi2Max - tempChi2Min) < 0.2:
        # 1D lattice through here
        chi2Loc = (tempChi2Max + tempChi2Min) / 2.
        currIter = 0
        startPoint = chi1Min - 0.02 * chi1Diff 
        while(1):
            currChi1 = startPoint + currIter * spacing1D
            if (currChi1 < tempChi1Lower) and (i != 0):
                currIter = currIter + 1
                continue
            elif (currChi1 > tempChi1Upper) and (i != 99):
                break
            elif (currChi1 > tempChi1Upper + 0.02*chi1Diff):
                break
            v1s.append(currChi1)
            v2s.append(chi2Loc)
            currIter = currIter + 1
    else:
        # Now we need 2D lattice
        lower1DBoundary = i
        break

# Next we start from the end and work backwards
for i in range(99,-1,-1):
    # Only need to do this if there is a lower boundary
    if lower1DBoundary is None:
        break
    # FIXME: Move this to a function, duplicated above!
    # FIXME: Maybe move all this to a generate_NS_lattice function
    tempChi1Lower = chi1Min + i * chi1Diff/100.
    tempChi1Upper = chi1Min + (i+1) * chi1Diff/100.
    lgc = (vals[0] > tempChi1Lower) & (vals[0] < tempChi1Upper)
    tempChi1 = vals[0][lgc]
    tempChi2 = vals[1][lgc]
    tempChi2Max = tempChi2.max()
    tempChi2Min = tempChi2.min()
    if (tempChi2Max - tempChi2Min) < 0.2:
        # 1D lattice through here
        chi2Loc = (tempChi2Max + tempChi2Min) / 2.
        currIter = 0  
        startPoint = chi1Min - 0.02 * chi1Diff
        while(1):
            currChi1 = startPoint + currIter * spacing1D
            if (currChi1 < tempChi1Lower) and (i != 0):
                currIter = currIter + 1
                continue
            elif (currChi1 > tempChi1Upper) and (i != 99):
                break
            elif (currChi1 > tempChi1Upper + 0.02*chi1Diff):
                break
            v1s.append(currChi1) 
            v2s.append(chi2Loc)
            currIter = currIter + 1
    else:
        # Now we need 2D lattice
        upper1DBoundary = i + 1
        break

# TESTING CODE: USE THIS TO TURN OFF THE 1D LATTICE, IE DO 2D EVERYWHERE
#lower1DBoundary = 0
#upper1DBoundary = 100
#v1s = []
#v2s = []

# Anything left is covered with a 2D hexagonal array
if lower1DBoundary is not None:
    # Need some 2D parts in the bank
    if lower1DBoundary == 0:
        lowerChi1 = chi1Min - 0.02*chi1Diff
    else:
        lowerChi1 = chi1Min + lower1DBoundary*chi1Diff/100.
    if upper1DBoundary == 100:
        upperChi1 = chi1Max + 0.02*chi1Diff
    else:
        upperChi1 = chi1Min + upper1DBoundary*chi1Diff/100.
    tempv1s, tempv2s = pycbc.tmpltbank.generate_hexagonal_lattice(upperChi1,\
                      lowerChi1, chi2Max + 0.02*chi2Diff,\
                      chi2Min - 0.02*chi2Diff, opts.min_match)
    v1s.extend(tempv1s)
    v2s.extend(tempv2s)

v1s = numpy.array(v1s)
v2s = numpy.array(v2s)

if opts.verbose:
    print>> sys.stdout, "There are %d points in the lattice." %(len(v1s))

# What follows is used to 
#   1) Check if the points are close to the physical space, if not reject
#   2) If the point is *within* the physical space find a physical point that
#      matches the position.
#   3) If the point is "close" to the physical space find a "close" physical
#      point within the allowed range. Close means within the specified
#      minimal mismatch.

# FIXME: Most of this should probably move to a function in pycbc.tmpltbank

# Choose an initial set of points to begin comparing points to physical space
rTotmass, rEta, rBeta, rSigma, rGamma, rSpin1z, rSpin2z = \
        pycbc.tmpltbank.get_random_mass(\
        2000000, opts.min_mass1, opts.max_mass1, opts.min_mass2,\
        opts.max_mass2,maxSpinMag, maxBHspin = maxSpinMag, \
        minTotalMass=opts.min_total_mass, maxTotalMass=opts.max_total_mass)
diff = (rTotmass*rTotmass * (1-4*rEta))**0.5
rMass1 = (rTotmass + diff)/2.
rMass2 = (rTotmass - diff)/2.
rChis = (rSpin1z + rSpin2z)/2.
# Here we have a set of m1s,m2s and mapped to Xis below
rXis = pycbc.tmpltbank.get_cov_params(rTotmass, rEta, rBeta, rSigma,\
        rGamma, rChis, opts.f0, evecs[opts.f_upper], evals[opts.f_upper], \
        evecsCV, opts.pn_order)

xis = (numpy.array(rXis)).T
physMasses = numpy.array([rTotmass, rEta, rSpin1z, rSpin2z])
physMasses = physMasses.T

# Sort the xis for easy access
v1smin = v1s.min()
v1smax = v1s.max()
v1sdiff = v1smax - v1smin
numv1bins = int(math.ceil(v1sdiff / 1.))
v2smin = v2s.min()
v2smax = v2s.max()
v2sdiff = v2smax - v2smin
numv2bins = int(math.ceil(v2sdiff / 1.))

sortedBins = {}

#for i in xrange(numv1bins):
#    print i
#    sortedBins[i] = {}
#    for j in xrange(numv2bins):
#        sortedBins[i][j] = []

if opts.verbose:
    print>> sys.stdout, "Sorting guide points at %f." %(elapsed_time())

bin_size = (opts.min_match)**0.5 * 3.

for iter, currXi in enumerate(xis):
    xi1 = currXi[0]
    xi2 = currXi[1]
    x1bin = int((xi1 - v1smin)/bin_size)
    x2bin = int((xi2 - v2smin)/bin_size)
    if not sortedBins.has_key(x1bin):
        sortedBins[x1bin] = {}
    if not sortedBins[x1bin].has_key(x2bin):
        sortedBins[x1bin][x2bin] = []
    if len(sortedBins[x1bin][x2bin]) < 100:
        sortedBins[x1bin][x2bin].append( (iter, xi1, xi2) )

if opts.verbose:
    print>> sys.stdout, "Converting to physical points at %f." %(elapsed_time())

# Now we start looping through all the points and either accept it, with a
# physical representation *or* accept it nudged toward the physical space
# *or* reject it if it is outside the physically allowed region. 

tempBank = []
temp_number = 0
req_match = 0.0001
temp_match = (opts.min_match)**0.5 * 3.
des_match = (opts.min_match)**0.5
# This can be used for debugging
#fileP = open('bank_file.dat','w')
for iter, (v1, v2) in enumerate(zip(v1s, v2s)):
    # First check if point is within the physical space
    # and find some example nearby physical points if it is.
    v1bin = int((v1 - v1smin)/bin_size)
    v2bin = int((v2 - v2smin)/bin_size)
    physBin = None
    for i in [v1bin, v1bin+1, v1bin-1]:
        if not sortedBins.has_key(i):
            continue
        for j in [v2bin, v2bin+1, v2bin-1]:
            if not sortedBins[i].has_key(j):
                continue
            physBin = [i,j]
            points = numpy.array(sortedBins[physBin[0]][physBin[1]])
            dist = (v1 - points[:,1])**2 + (v2 - points[:,2])**2
            if dist.min() > 0.5:
                physBin = None
            break
        if physBin:
            break
    else:
        # No nearby physical points found: continue
        continue
    iters = points[:,0]
    bestXis = points[dist.argmin(),1:]
    bestMasses = physMasses[points[dist.argmin(),0]]
    
    # Reject point if it is too far from physical space
    if dist.min() > temp_match:
        continue
    masses = pycbc.tmpltbank.get_physical_covaried_masses([v1,v2],\
               copy.deepcopy(bestMasses), copy.deepcopy(bestXis), opts.f0,\
               req_match, opts.pn_order, evecs[opts.f_upper], \
               evals[opts.f_upper], evecsCV, opts.max_mass1, opts.min_mass1, \
               opts.max_mass2, opts.min_mass2, maxSpinMag, maxSpinMag, \
               giveUpThresh = 10, minTotalMass=opts.min_total_mass, \
               maxTotalMass=opts.max_total_mass)

    # If point is still not close enough to desired space, remove it
    if masses[5] > des_match * 1.1:
        continue
    # Add the two masses (masses[0],masses[1]) to the list. For consistency
    # we also add spin1z and spin2z (masses[2] and masses[3]) but here these
    # will always be 0.

    tempBank.append([masses[0], masses[1], masses[2], masses[3]])

    # This can be used for debugging
    # print >>fileP, masses[0],masses[1],masses[2],masses[3],masses[4],\
    #  masses[5],masses[6],masses[7],masses[8],masses[9],v1,v2

if opts.verbose:
    print>> sys.stdout, "Physical bank generated at %f." %(elapsed_time())

# Currently this is hardcoded to dump as a sngl_inspiral table. But this is
# easily changed.

pycbc.tmpltbank.output_sngl_inspiral_table(opts.output_file, tempBank, moments,\
         opts.f0, calculate_ethinca_comps=opts.calculate_ethinca_metric,\
         programName=__program__,optDict=opts.__dict__,\
         comment="", ifos=[""], version=pycbc.version.git_hash,\
         cvs_repository='pycbc/'+pycbc.version.git_branch,\
         cvs_entry_time=pycbc.version.date)

if opts.verbose:
    print>> sys.stdout, "Done at %f." %(elapsed_time())

