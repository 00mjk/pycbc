#!/bin/bash
# Redirect stdout ( > ) into a named pipe ( >() ) running "tee"
set -e

mkdir -p workflow
echo "${0} ${@}" > workflow/pycbc-submit-dax-command.txt
echo "Executing on `hostname` in directory `pwd` at `date`" > workflow/pycbc-submit-dax-log.txt

exec > >(tee -a workflow/pycbc-submit-dax-log.txt)

# Without this, only stdout would be captured - i.e. your
# log file would not contain any error messages.
# SEE answer by Adam Spiers, which keeps STDERR a seperate stream -
# I did not want to steal from him by simply adding his answer to mine.
exec 2>&1

DAX_FILE=""
CACHE_FILE=0
LOCAL_PEGASUS_DIR=""
ACCOUNTING_GROUP=""
NO_ACCOUNTING_GROUP=0
PEGASUS_PROPERTIES=""
SITE_LIST=""
STAGING_SITES=""
TRANSFORMATION_CATALOG=""
LOCAL_GSIFTP_SERVER=""
NO_CREATE_PROXY=0
SUBMIT_DAX="--submit"

echo "# Properties set on command line" > extra-properties.conf
rm -f _reuse.cache
touch _reuse.cache
rm -f *-extra-site-properties.xml

GETOPT_CMD=`getopt -o d:c:g:a:p:P:s:S:k:t:Fknl:h --long dax:,cache-file:,local-gsiftp-server:,accounting-group:,pegasus-properties:,append-pegasus-property:,execution-sites:,staging-sites:,append-site-profile:,transformation-catalog:,force-no-accounting-group,no-create-proxy,no-submit,local-dir:,help -n 'pycbc_submit_dax' -- "$@"`
eval set -- "$GETOPT_CMD"

while true ; do
  case "$1" in
    -d|--dax)
      case "$2" in
        "") shift 2 ;;
        *) DAX_FILE=$2 ; shift 2 ;;
      esac ;;
    -c|--cache-file)
      case "$2" in
        "") shift 2 ;;
        *) CACHE_FILE=1
           if [ -e $2 ] ; then 
             cat $2 >> _reuse.cache
             else
               echo "Error: cache file $2 not found"
               exit 1
             fi
           shift 2 ;;
      esac ;;
    -g|--local-gsiftp-server)
      case "$2" in
        "") shift 2 ;;
        *) LOCAL_GSIFTP_SERVER=$2 ; shift 2 ;;
      esac ;;
    -a|--accounting-group)
      case "$2" in
        "") shift 2 ;;
        *) export ACCOUNTING_GROUP=$2 ; shift 2 ;;
      esac ;;
    -p|--pegasus-properties)
      case "$2" in
        "") shift 2 ;;
        *) PEGASUS_PROPERTIES=$2 ; shift 2 ;;
      esac ;;
    -P|--append-pegasus-property)
      case "$2" in
        "") shift 2 ;;
        *) echo $2 >> extra-properties.conf ; shift 2 ;;
      esac ;;
    -s|--execution-sites)
      case "$2" in
        "") shift 2 ;;
        *) SITE_LIST=$2 ; shift 2 ;;
      esac ;;
    -S|--staging-sites)
      case "$2" in
        "") shift 2 ;;
        *) STAGING_SITES="--staging-site $2" ; shift 2 ;;
      esac ;;
    -k|--append-site-profile)
      case "$2" in
        "") shift 2 ;;
        *) APPEND_SITE_PROFILE_ARRAY=(${2//:/ })
           APPEND_SITE=${APPEND_SITE_PROFILE_ARRAY[0]}
           APPEND_SITE_NS_KEY=(${APPEND_SITE_PROFILE_ARRAY[1]//\|/ })
           APPEND_SITE_VALUE=${APPEND_SITE_PROFILE_ARRAY[2]}
           echo "    <profile namespace=\"${APPEND_SITE_NS_KEY[0]}\" key=\"${APPEND_SITE_NS_KEY[1]}\">${APPEND_SITE_VALUE}</profile>" >> ${APPEND_SITE}-extra-site-properties.xml
        shift 2 ;;
      esac ;;
    -t|--transformation-catalog)
      case "$2" in
        "") shift 2 ;;
        *) TRANSFORMATION_CATALOG=$2 ; shift 2 ;;
      esac ;;
    -F|--force-no-accounting-group) NO_ACCOUNTING_GROUP=1 ; shift ;;
    -k|--no-create-proxy) NO_CREATE_PROXY=1 ; shift ;;
    -n|--no-submit) SUBMIT_DAX="" ; shift ;;
    -l|--local-dir)
      case "$2" in
        "") shift 2 ;;
        *) LOCAL_PEGASUS_DIR=$2 ; shift 2 ;;
      esac ;;
    -h|--help)
      echo "usage: pycbc_submit_dax [-h] --dax DAX [optional arguments]"
      echo
      echo "required arguments:"
      echo "  -d, --dax DAX           name of the dax file to plan"
      echo
      echo "workflow submission required one of:"
      echo "  -a, --accounting-group GROUP tagged string used for site "
      echo "                               resource accounting."
      echo "  -F, --force-no-accounting-group submit without an accounting"
      echo "                               group. Will cause condor submission"
      echo "                               to fail on LIGO Data Grid clusters"
      echo
      echo "optional arguments:"
      echo "  -h, --help              show this help message and exit"
      echo "  -c, --cache-file FILE   replica cache file for data reuse"
      echo "  -g, --local-gsiftp-server HOST provide a gsiftp url on HOST"
      echo "                                 for the local site storage"
      echo "                                 and scratch directories" 
      echo "  -p, --pegasus-properties FILE use the specified file as"
      echo "                               the pegasus properties file"
      echo "  -P, --append-pegasus-property STRING add the extra property"
      echo "                                          specified by the argument"
      echo "  -s, --execution-sites A,B,C specify a comma separated list"
      echo "                               of execution sites that will be"
      echo "                               used in addition to the local site"
      echo "  -S, --staging-sites A=X,B=Y,C=Z  comma separated list of key=value"
      echo "                                   pairs, where the key is the"
      echo "                                   execution site and value is the"
      echo "                                   staging site for that execution site"
      echo "  -k, --append-site-profile SITE:NAMESPACE|KEY:VALUE"
      echo "                               append the profile determined by"
      echo "                               NAMESPACE, KEY, and VALUE to the"
      echo "                               site catalog entry for SITE"
      echo "  -t, --transformation-catalog FILE pass the specified"
      echo "                                   transformation catalog to Pegasus"
      echo "  -k, --no-create-proxy   Do not run ligo-proxy-init and assume"
      echo "                             that the user has a valid grid proxy"
      echo "  -n, --no-submit         Plan the DAX but do not submit it"
      echo "  -l, --local-dir         Directory to put condor files under"
      echo
      echo "If the environment variable TMPDIR is set then this is prepended to the "
      echo "path to the temporary workflow execte directory passed to pegasus-plan."
      echo "If the --local-dir option is not given."
      echo
      echo "If the environment variable PEGASUS_FILE_DIRECTORY is set then the"
      echo "script will look there for pegasus site catalog and configuration"
      echo "otherwise, the script will look for this directory by querying the"
      echo "pycbc.workflow module."
      echo
      echo "If the environment variable PEGASUS_SITE_CATALOG_PATH is set then the"
      echo "script will look for site catalog templates in this directory."
      echo "Site catalog templates may contain other environment variables that"
      echo "must be set in order for them to be rendered correctly."
      echo
      exit 0 ;;
    --) shift ; break ;;
    *) echo "Internal error!" ; exit 1 ;;
  esac
done

if [ "x$DAX_FILE" == "x" ]; then
  echo "Error: --dax must be specified. Use --help for options."
   exit 1
fi

if [ "x$ACCOUNTING_GROUP" == "x" ] && [ $NO_ACCOUNTING_GROUP == 0 ]; then
  echo "Error: You must specify and accounting group with --accounting-group or"
  echo "override this check with --force-no-accounting-group. If you do not specify"
  echo "an accounting group, job submission will fail on the LIGO Data Grid."
  echo
  echo "For a list of available LIGO Data Grid accounting group tags, see"
  echo "   https://ldas-gridmon.ligo.caltech.edu/ldg_accounting/user"
  exit 1
fi

if [ $NO_CREATE_PROXY == 0 ]; then
  # Force the user to create a new grid proxy
  LIGO_USER_NAME=""
  while true; do
    read -p "Enter your LIGO.ORG username in (e.g. albert.einstein): " LIGO_USER_NAME
    echo
    if [ ! -z $LIGO_USER_NAME ] ; then
      break
    fi
  done
  unset X509_USER_PROXY
  ligo-proxy-init $LIGO_USER_NAME || exit 1
fi

#Make a directory for the submit files
SUBMIT_DIR=`mktemp --tmpdir=${LOCAL_PEGASUS_DIR} -d pycbc-tmp.XXXXXXXXXX`

#Make sure the directory is world readable
chmod 755 $SUBMIT_DIR

# find the site-local template directory
if [ -z $PEGASUS_FILE_DIRECTORY ] ; then
  PEGASUS_FILE_DIRECTORY=`python -c 'from pycbc.workflow import PEGASUS_FILE_DIRECTORY;print PEGASUS_FILE_DIRECTORY'`
fi

# Create the site catalog
export LOCAL_SITE_PATH=${PWD}
if [ -z $LOCAL_GSIFTP_SERVER ] ; then
  LOCAL_SITE_URL="file://${LOCAL_SITE_PATH}"
else
  LOCAL_SITE_URL="gsiftp://${LOCAL_GSIFTP_SERVER}${LOCAL_SITE_PATH}"
fi
export LOCAL_SITE_URL

# add the local site
if [ -z $SITE_LIST ] ; then
  SITE_LIST="local"
else
  SITE_LIST="local,${SITE_LIST}"
fi

if [ -z ${PEGASUS_SITE_CATALOG_PATH} ] ; then
  PEGASUS_SITE_CATALOG_PATH=${PEGASUS_FILE_DIRECTORY}
fi

# create the site catalog template
echo 'cat <<END_OF_TEXT' > site-catalog.sh

cat << EOF >> site-catalog.sh
<?xml version="1.0" encoding="UTF-8"?>
<sitecatalog xmlns="http://pegasus.isi.edu/schema/sitecatalog" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://pegasus.isi.edu/schema/sitecatalog http://pegasus.isi.edu/schema/sc-4.0.xsd" version="4.0">
EOF

OLD_IFS=${IFS}
IFS=','
read -ra SITE <<< "$SITE_LIST"
IFS=${OLD_IFS}
for s in "${SITE[@]}"; do
  SITE_TEMPLATE=$PEGASUS_SITE_CATALOG_PATH/${s}-site-template.xml
  if [ ! -e ${SITE_TEMPLATE} ] ; then
    echo "Error: Could not find site catalog template for site ${s}"
    exit 1
  else
    cat $SITE_TEMPLATE >> site-catalog.sh
    if [ -e ${s}-extra-site-properties.xml ] ; then
      cat ${s}-extra-site-properties.xml >> site-catalog.sh
    fi
    echo "  </site>" >> site-catalog.sh
  fi
done

cat << EOF >> site-catalog.sh
</sitecatalog>
EOF
echo 'END_OF_TEXT' >> site-catalog.sh

# write out the site catalog
bash site-catalog.sh > site-catalog.xml

# Plan the workflow
echo "Generating concrete workflow"

# cache the pegasus config
if [ -z ${PEGASUS_PROPERTIES} ] ; then
  cp $PEGASUS_FILE_DIRECTORY/pegasus-properties.conf ./pegasus-properties.conf
else
  cp ${PEGASUS_PROPERTIES} ./pegasus-properties.conf
fi

# add a transformation catalog, if specified
if [ ! -z ${TRANSFORMATION_CATALOG} ] ; then
  cp ${TRANSFORMATION_CATALOG} ./transformation-catalog.txt
  echo >> pegasus-properties.conf
  echo "pegasus.catalog.transformation Text" >> pegasus-properties.conf
  echo "pegasus.catalog.transformation.file ${PWD}/transformation-catalog.txt" >> pegasus-properties.conf
fi

echo >> pegasus-properties.conf
cat extra-properties.conf >> pegasus-properties.conf

if [ $CACHE_FILE == 0 ]; then
  pegasus-plan --conf ./pegasus-properties.conf -d $DAX_FILE --sites $SITE_LIST $STAGING_SITES -o local --dir $SUBMIT_DIR --cleanup inplace --relative-submit-dir work --cluster label $SUBMIT_DAX 
else
  pegasus-plan --conf ./pegasus-properties.conf -d $DAX_FILE --sites $SITE_LIST $STAGING_SITES -o local --dir $SUBMIT_DIR --cleanup inplace --cache _reuse.cache --relative-submit-dir work --cluster label $SUBMIT_DAX
fi

echo

# Copy planning information into workflow directory so it can be displayed on the results page
mkdir -p workflow/pegasus
cp pegasus-properties.conf workflow/pegasus
cp site-catalog.xml workflow/pegasus
cp _reuse.cache workflow/pegasus/data-reuse.cache
cp $SUBMIT_DIR/work/braindump.txt workflow/pegasus

# copy the main dax and output.map to the workflow directory
cp $DAX_FILE workflow
if [ -e output.map ] ; then
  cp output.map workflow
fi

# ugly shell to extract the sub-dax names from the uberdax xml
for dax in `egrep '<[:blank:]*dax' ${DAX_FILE} | tr ' ' \\\n | grep file | awk -F= '{print $2}' | tr -d '">'` ; do 
  cp ${dax} workflow
  map=`basename ${dax} .dax`.map
  if [ -e ${map} ] ; then
    cp ${map} workflow
  fi
done

rm -f submitdir
ln -sf $SUBMIT_DIR submitdir

echo pegasus-status $SUBMIT_DIR/work > status
chmod 755 status

echo pegasus-analyzer $SUBMIT_DIR/work > debug
chmod 755 debug

echo pegasus-remove $SUBMIT_DIR/work > stop
chmod 755 stop

echo pegasus-run $SUBMIT_DIR/work > start
chmod 755 start

if [ -z ${SUBMIT_DAX} ] ; then 
  echo
  echo "WARNING: DAX planned but not submitted. No dashboard entry has been created and"
  echo "         the workflow section of results page will not show a dashboard URL."
  echo "         You must run this script without the --no-submit option if this is a"
  echo "         production run."
  echo
  exit 0
fi

if [ ! -e ${HOME}/.pegasus/workflow.db ] ; then
  echo "WARNING: Could not find Pegasus dashboard database in ${HOME}/.pegasus"
  echo "         Workflow has been submitted but the results page will not contain"
  echo "         a link to the dashboard page. If this is a production workflow,"
  echo "         please remove the workflow, check for the origin of this error,"
  echo "         and re-submit the workflow by re-running this script."
  echo
  exit 1
fi
  
sleep 1
WORKFLOW_ID_STRING=`sqlite3 -csv ${HOME}/.pegasus/workflow.db "select submit_hostname,wf_id,wf_uuid from master_workflow where submit_dir = '${SUBMIT_DIR}/work';"`

if [ -z $WORKFLOW_ID_STRING ] ; then
  echo "WARNING: Could not find the workflow in the Pegasus dashboard database."
  echo "         Workflow has been submitted but the results page will not contain"
  echo "         a link to the dashboard page. If this is a production workflow,"
  echo "         please remove the workflow, check for the origin of this error,"
  echo "         and re-submit the workflow by re-running this script."
  echo
  exit 1
fi

WORKFLOW_ID_ARRAY=(${WORKFLOW_ID_STRING//,/ })
DASHBOARD_URL="https://${WORKFLOW_ID_STRING[0]}/pegasus/u/${USER}/r/${WORKFLOW_ID_ARRAY[1]}/w?wf_uuid=${WORKFLOW_ID_ARRAY[2]}"

echo ${DASHBOARD_URL} > workflow/pegasus-dashboard-url.txt

echo "Workflow submission completed successfully."
echo 
echo "The Pegasus dashboard URL for this workflow is:"
echo "  ${DASHBOARD_URL}"
echo
echo "Note that it make take a while for the dashboard entry to appear while the workflow"
echo "is parsed by the dashboard. The delay can be on the order of one hour for very large"
echo "workflows."
echo

exit 0
