#!/usr/bin/env /usr/bin/python

# Copyright (C) 2014 Alex Nitz
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 3 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

import logging
import argparse
from pycbc import vetoes, psd, waveform, events, strain, scheme, fft, DYN_RANGE_FAC, filter
from pycbc.filter import matched_filter_core, sigmasq, make_frequency_series
from pycbc.types import TimeSeries, FrequencySeries, zeros, float32, complex64
import pycbc.fft.fftw

parser = argparse.ArgumentParser(usage='',
    description="Find single detector gravitational-wave triggers.")

parser.add_argument("-V", "--verbose", action="store_true", 
                  help="print extra debugging information", default=False )
parser.add_argument("--output", type=str)

parser.add_argument("--bank-file", type=str)
parser.add_argument("--snr-threshold", 
                  help="SNR threshold for trigger generation", type=float)
parser.add_argument("--newsnr-threshold", type=float, metavar='THRESHOLD',
                    help="Cut triggers with NewSNR less than THRESHOLD")
parser.add_argument("--low-frequency-cutoff", type=float,
                  help="The low frequency cutoff to use for filtering (Hz)")
                  
parser.add_argument("--approximant", type=str,
                  help="The name of the approximant to use for filtering")
parser.add_argument("--order", type=str,
                  help="The integer half-PN order at which to generate"
                       " the approximant.")
taper_choices = ["start","end","startend"]
parser.add_argument("--taper-template", choices=taper_choices,
                  help="For time-domain approximants, taper the start and/or "
                       "end of the waveform before FFTing.")

parser.add_argument("--cluster-method", choices=["template", "window"])
parser.add_argument("--cluster-window", type=float, default = -1,
                  help="Length of clustering window in seconds")
parser.add_argument("--cluster-before-vetoes", action='store_true', default=False,
                  help="Cluster above-threshold SNR values before doing "
                       "chisq calculations."
                   )
parser.add_argument("--maximization-interval", type=float, default=0,
                  help="Maximize triggers over the template bank (ms)")

parser.add_argument("--bank-veto-bank-file", type=str)

parser.add_argument("--chisq-bins", type=int, default=0)
parser.add_argument("--chisq-threshold", type=float, default=0)
parser.add_argument("--chisq-delta", type=float, default=0)

parser.add_argument("--autochi-number-points", type=int, default=0)
parser.add_argument("--autochi-stride", type=int, default=0)
parser.add_argument("--autochi-onesided", action='store_true', default=False)
parser.add_argument("--snr-precheck", action='store_true')
parser.add_argument("--snr-precheck-factor", type=int)
parser.add_argument("--snr-precheck-threshold", type=float)

parser.add_argument("--user-tag", type=str, metavar="TAG", help="""
                    This is used to identify FULL_DATA jobs for 
                    compatibility with pipedown post-processing. 
                    Option will be removed when no longer needed.""")

# Add options groups
psd.insert_psd_option_group(parser)
strain.insert_strain_option_group(parser)
strain.StrainSegments.insert_segment_option_group(parser)
scheme.insert_processing_option_group(parser)
fft.insert_fft_option_group(parser)

opt = parser.parse_args()

# Check that the values returned for the options make sense
psd.verify_psd_options(opt, parser)
strain.verify_strain_options(opt, parser)
strain.StrainSegments.verify_segment_options(opt, parser)
scheme.verify_processing_options(opt, parser)
fft.verify_fft_options(opt,parser)

if opt.verbose:
    log_level = logging.DEBUG
else:
    log_level = logging.WARN
logging.basicConfig(format='%(asctime)s : %(message)s', level=log_level)

ctx = scheme.from_cli(opt)
gwstrain = strain.from_cli(opt, DYN_RANGE_FAC)
strain_segments = strain.StrainSegments.from_cli(opt, gwstrain)

with ctx:
    fft.from_cli(opt)

    if opt.fftw_input_float_wisdom_file is not None:
        fft.fftw.import_single_wisdom_from_filename(opt.fftw_input_float_wisdom_file)

    if opt.fftw_input_double_wisdom_file is not None:
        fft.fftw.import_double_wisdom_from_filename(opt.fftw_input_double_wisdom_file)
                          
    flow = opt.low_frequency_cutoff                                                               
    flen = strain_segments.freq_len
    tlen = strain_segments.time_len
    delta_f = strain_segments.delta_f

    logging.info("Making frequency-domain data segments")
    segments = strain_segments.fourier_segments()

    logging.info("Computing noise PSD")
    psd = psd.from_cli(opt, flen, delta_f, flow, gwstrain, DYN_RANGE_FAC)
    psd = psd.astype(float32)                              
    bank_chisq = vetoes.SingleDetBankVeto(opt.bank_veto_bank_file, 
                                          opt.approximant, psd, segments, flow, 
                                          phase_order=opt.order)                                       
    power_chisq = vetoes.SingleDetPowerChisq(opt.chisq_bins)
 
    autochisq = vetoes.SingleDetAutoChisq(opt.autochi_stride, opt.snr_threshold,
                                    opt.autochi_number_points, opt.autochi_onesided)
  
    logging.info("Overwhitening frequency-domain data segments")
    for seg in segments:
        seg /= psd

    names =  ['time_index', 'snr', 'chisq', 'bank_chisq', 'cont_chisq']
    event_mgr = events.EventManager(opt, names,
                         [int, complex64, float32, float32, float32, float32], psd=psd)

    logging.info("Read in template bank")
    bank = waveform.FilterBank(opt.bank_file, opt.approximant, flen, delta_f, 
                    flow, dtype=complex64, psd=psd, phase_order=opt.order,
                    taper=opt.taper_template, out=zeros(tlen, dtype=complex64))

    snr_mem = zeros(tlen, dtype=complex64)
    corr_mem = zeros(tlen, dtype=complex64)

    for t_num, template in enumerate(bank):  
        event_mgr.new_template(tmplt=template.params, sigmasq=template.sigmasq)  
               
        if opt.cluster_method == "window":
            cluster_window = int(opt.cluster_window * gwstrain.sample_rate)
        elif opt.cluster_method == "template":
            cluster_window = int(template.chirp_length * gwstrain.sample_rate)

        for s_num, stilde in enumerate(segments):                 
            logging.info("Filtering template %d/%d segment %d/%d" % \
                         (t_num + 1, len(bank), s_num + 1, len(segments)))  
                         
            idx, snrv, corr, norm = filter.dynamic_rate_thresholded_matched_filter(template, 
                                                    stilde, template.sigmasq,
                                                    opt.snr_precheck_factor,
                                                    opt.snr_precheck_threshold,
                                                    opt.snr_threshold,
                                                    stilde.analyze,
                                                    low_frequency_cutoff=flow)                                                                                                   
            if len(idx) == 0:
                continue            
            logging.info("%s points above threshold" % str(len(idx)))    
            
            #if len(idx) > 0:
            #    print snrv*norm  
            continue
                    
            if opt.cluster_before_vetoes:    
                idx, snrv = events.cluster_reduce(idx, snrv, cluster_window) 
                logging.info("%s points after clustering" % str(len(idx))) 
                
            bank_chisqv = bank_chisq.values(template, s_num, snr, norm, 
                                            idx+stilde.analyze.start)
            power_chisqv = power_chisq.values(corr, snr, norm, psd, 
                                            idx+stilde.analyze.start, 
                                            template, bank, flow)   
            snrv *= norm
            
            if opt.autochi_number_points:
                auto_chisqv = autochisq.values(snr*norm, corr, hautocorr=None, 
                    indices=idx+stilde.analyze.start, template=template, psd=psd, 
                    low_frequency_cutoff=flow)

            idx += stilde.cumulative_index          

            if (opt.autochi_number_points):
               vals = [idx, snrv, power_chisqv, bank_chisqv, auto_chisqv[:, 2]]
            else:
               vals = [idx, snrv, power_chisqv, bank_chisqv, None]

            event_mgr.add_template_events(names, vals)
            
        event_mgr.cluster_template_events("time_index", "snr", cluster_window) 
        event_mgr.finalize_template_events()   
        
logging.info("Found %s triggers" % str(len(event_mgr.events)))

if opt.chisq_threshold and opt.chisq_bins:
    logging.info("Removing triggers with poor chisq")
    event_mgr.chisq_threshold(opt.chisq_threshold, opt.chisq_bins, 
                              opt.chisq_delta)
    logging.info("%d remaining triggers" % len(event_mgr.events))

if opt.newsnr_threshold and opt.chisq_bins:
    logging.info("Removing triggers with NewSNR below threshold")
    event_mgr.newsnr_threshold(opt.newsnr_threshold)
    logging.info("%d remaining triggers" % len(event_mgr.events))

if opt.maximization_interval:       
    logging.info("Maximizing triggers over %s ms window" % opt.maximization_interval)
    window = int(opt.maximization_interval * gwstrain.sample_rate / 1000)
    event_mgr.maximize_over_bank("time_index", "snr", window)
    logging.info("%d remaining triggers" % len(event_mgr.events))

logging.info("Writing out triggers")
event_mgr.write_events(opt.output)


if opt.fftw_output_float_wisdom_file:
    fft.fftw.export_single_wisdom_to_filename(opt.fftw_output_float_wisdom_file)

if opt.fftw_output_double_wisdom_file:
    fft.fftw.export_double_wisdom_to_filename(opt.fftw_output_double_wisdom_file)

logging.info("Finished")
